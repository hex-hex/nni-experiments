{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Embedding, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import RandomUniform, he_normal,he_uniform\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='model2ai'\n",
    "seed=2020\n",
    "embedding_init = RandomUniform(seed=seed)\n",
    "relu_init = he_uniform(seed=seed)\n",
    "embeddings_regu =l2(1e-6)\n",
    "n_latent_factors = 16\n",
    "loss_threshold = 0.5 #no scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.5, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'ml100k':'http://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
    "            'ml20m':'http://files.grouplens.org/datasets/movielens/ml-20m.zip',\n",
    "            'mllatestsmall':'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip',\n",
    "            'ml10m':'http://files.grouplens.org/datasets/movielens/ml-10m.zip',\n",
    "            'ml1m':'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:  ['ml100k', 'ml20m', 'mllatestsmall', 'ml10m', 'ml1m']\n",
      "Dataset name = ml100k\n",
      "You selected ml100k\n"
     ]
    }
   ],
   "source": [
    "print('Available datasets: ', [key for key in datasets])\n",
    "dt = input('Dataset name = ')\n",
    "print('You selected {}'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ml-100k.zip\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "dt_name = os.path.basename(datasets[dt])\n",
    "\n",
    "print('Downloading {}'.format(dt_name))\n",
    "with urllib.request.urlopen(datasets[dt]) as response, open('./sample_data/'+dt_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "print('Download completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./sample_data/'+dt_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./sample_data/')\n",
    "dt_dir_name = os.path.splitext(dt_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "def list_files(startpath):\n",
    "    print(startpath)\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "dirs = [x[0] for x in os.walk(\"./sample_data\")]\n",
    "#print(list(dirs[0]))\n",
    "ml = filter(lambda dirName: dirName if ('ml' in dirName) else '', list(dirs))\n",
    "dt_dir_name= list(ml)[1]\n",
    "print(dt_dir_name)\n",
    "#list_files('./sample_data/'+dt_dir_name +'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100k \n",
    "if dt=='ml100k':\n",
    "    dataset = pd.read_csv(dt_dir_name+\"/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n",
    "#ml1m\n",
    "if dt=='ml1m':\n",
    "    dataset=pd.read_csv(dt_dir_name +'/'+ 'ratings.dat', delimiter='\\:\\:', names=['user_id', 'item_id', 'rating', 'timestamp'])  \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

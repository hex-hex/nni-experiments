{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbfhRLv0zejb"
   },
   "source": [
    "@Editors: Tung Nguyen, Mo Nguyen, Jian Yu\n",
    "\n",
    "@base: 16/01/20 discussion\n",
    "\n",
    "Main changes: \n",
    "\n",
    "- the input is the rating matrix\n",
    "- Use he_uniform init for relu\n",
    "- No batch normalization and dropout for encoder\n",
    "- New metrics for every output:\n",
    "\n",
    "      metrics={'output':['binary_accuracy','Precision'], \n",
    "                         'decoder':'mse', \n",
    "                         'decoder2':'mse'})\n",
    "\n",
    "##Problem\n",
    "\n",
    "- The MLP seems to be not updating with implicit data!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWjyzcXW54GG"
   },
   "source": [
    "#Model implementation framework\n",
    "\n",
    "TF2.0 and Keras implementation\n",
    "\n",
    "- Create GMF model\n",
    "    - Create helper methods: User/item latent\n",
    "    - Create loss functions\n",
    "    - Handle input $u_i, v_j$\n",
    "    - Handle output $\\hat{r}_{ij}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koO06XoHRo_K"
   },
   "source": [
    "## Organise imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PhlM3OtBzRdr",
    "outputId": "0bd39391-c250-4d7d-ff7d-ec5363f4634a"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#import\n",
    "#tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.layers import Input, Dense, Concatenate, Embedding, Dropout, BatchNormalization\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.regularizers import l1, l2, l1_l2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7e8HEOWFPfY"
   },
   "outputs": [],
   "source": [
    "#dt_dir_name= \"C:/Users/jiyu/Desktop/Mo/sample_data/ml-1m\"\n",
    "dt_dir_name= \"C:/Users/thinguyen/Desktop/PhD_2020/Python Code/GNN/Mo/sample_data/ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100k \n",
    "dataset = pd.read_csv(dt_dir_name+\"/u.data\",sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))\n",
    "\n",
    "#ml1m\n",
    "#dataset=pd.read_csv(dt_dir_name +'/'+ 'ratings.dat', delimiter='\\:\\:', names=['user_id', 'item_id', 'rating', 'timestamp'])  \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yd2F19dTFmpi"
   },
   "outputs": [],
   "source": [
    "uids = np.sort(dataset.user_id.unique())\n",
    "iids = np.sort(dataset.item_id.unique())\n",
    "\n",
    "n_users = len(uids)\n",
    "n_items = len(iids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XrPNkCqOsY3h",
    "outputId": "46faf35a-1d01-4f73-ba83-663d55bbef1f"
   },
   "outputs": [],
   "source": [
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y50GEUeWrgYL"
   },
   "outputs": [],
   "source": [
    "#reindex from 0 ids\n",
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values\n",
    "#createMFModel(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYNfcOkbFaxL"
   },
   "source": [
    "#Create deep embedding using MLP of the [model](https://drive.google.com/file/d/1kN5loA18WyF1-I7BskOw6c9P1bdArxk7/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUH0ZY-U9GUa"
   },
   "source": [
    "## Create deep autoencoder \n",
    "\n",
    "Reference: [keras](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JkJvoIbS4gd"
   },
   "source": [
    "##Turn original dataset to negative sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYxI9uKCQ9Gl"
   },
   "outputs": [],
   "source": [
    "#Version 1.2 (flexible + superfast negative sampling uniform)\n",
    "import random\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "def neg_sampling(ratings_df, n_neg=1, neg_val=0, pos_val=1, percent_print=5):\n",
    "  \"\"\"version 1.2: 1 positive 1 neg (2 times bigger than the original dataset by default)\n",
    "\n",
    "    Parameters:\n",
    "    input rating data as pandas dataframe: userId|movieId|rating\n",
    "    n_neg: include n_negative / 1 positive\n",
    "\n",
    "    Returns:\n",
    "    negative sampled set as pandas dataframe\n",
    "            userId|movieId|interact (implicit)\n",
    "  \"\"\"\n",
    "  sparse_mat = scipy.sparse.coo_matrix((ratings_df.rating, (ratings_df.user_id, ratings_df.item_id)))\n",
    "  dense_mat = np.asarray(sparse_mat.todense())\n",
    "  print(dense_mat.shape)\n",
    "\n",
    "  nsamples = ratings_df[['user_id', 'item_id']]\n",
    "  nsamples['rating'] = nsamples.apply(lambda row: 1, axis=1)\n",
    "  length = dense_mat.shape[0]\n",
    "  printpc = int(length * percent_print/100)\n",
    "\n",
    "  nTempData = []\n",
    "  i = 0\n",
    "  start_time = time.time()\n",
    "  stop_time = time.time()\n",
    "\n",
    "  extra_samples = 0\n",
    "  for row in dense_mat:\n",
    "    if(i%printpc==0):\n",
    "      stop_time = time.time()\n",
    "      print(\"processed ... {0:0.2f}% ...{1:0.2f}secs\".format(float(i)*100 / length, stop_time - start_time))\n",
    "      start_time = stop_time\n",
    "\n",
    "    n_non_0 = len(np.nonzero(row)[0])\n",
    "    zero_indices = np.where(row==0)[0]\n",
    "    if(n_non_0 * n_neg + extra_samples >= len(zero_indices)):\n",
    "      print(i, \"non 0:\", n_non_0,\": len \",len(zero_indices))\n",
    "      neg_indices = zero_indices.tolist()\n",
    "      extra_samples = n_non_0 * n_neg + extra_samples - len(zero_indices)\n",
    "    else:\n",
    "      neg_indices = random.sample(zero_indices.tolist(), n_non_0 * n_neg + extra_samples)\n",
    "      extra_samples = 0\n",
    "\n",
    "    nTempData.extend([(uu, ii, rr) for (uu, ii, rr) in zip(np.repeat(i, len(neg_indices))\n",
    "                    , neg_indices, np.repeat(neg_val, len(neg_indices)))])\n",
    "    i+=1\n",
    "\n",
    "  nsamples=nsamples.append(pd.DataFrame(nTempData, columns=[\"user_id\",\"item_id\", \"rating\"]),ignore_index=True)\n",
    "  nsamples.reset_index(drop=True)\n",
    "  return nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "y_14eDLzQ5tY",
    "outputId": "8905f155-dc16-4e34-d038-ee817719b031"
   },
   "outputs": [],
   "source": [
    "neg_dataset = neg_sampling(dataset, n_neg=1)\n",
    "neg_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFc7u4Y0kk0o"
   },
   "source": [
    "#Create rating (uxi) matrix with implicit data\n",
    "\n",
    "Change rating data -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_y5-tWBKkL3h"
   },
   "outputs": [],
   "source": [
    "def create_rating_matrix(u_i_r_df):\n",
    "  rating_matrix = np.zeros(shape =(n_users, n_items), dtype=int)\n",
    "  for row in u_i_r_df.itertuples(index=False):\n",
    "    rating_matrix[int(row[0]), int(row[1])] = int(row[2])\n",
    "  return rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "1dDyDUvisLY_",
    "outputId": "921ab878-2ca1-41f5-e014-eabf9db7687f"
   },
   "outputs": [],
   "source": [
    "rating_matrix = create_rating_matrix(neg_dataset)\n",
    "rating_matrix.shape, rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "gps_m4aaCRo2",
    "outputId": "e589425e-bdb5-4fc0-e2de-ddd895dea2b1"
   },
   "outputs": [],
   "source": [
    "neg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "uLHgC7JzB7m7",
    "outputId": "b4582a4b-1f4a-4ff1-97b6-2ff5c2c93a28"
   },
   "outputs": [],
   "source": [
    "rating_matrix2 = create_rating_matrix(dataset)\n",
    "rating_matrix2.shape, rating_matrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUEeZg2uC78z"
   },
   "source": [
    "##Create train, test, val sets from neg_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXY34jFnUd8A"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(neg_dataset, test_size=0.2, random_state=2020)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=2020)\n",
    "\n",
    "# train.reset_index(inplace=True, drop=True)\n",
    "# test.reset_index(inplace=True, drop=True)\n",
    "# val.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "JcnLtRI9U0Kv",
    "outputId": "ed31eabe-f18d-41c2-de4e-0adb7be338e0"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7owpsQpJBER"
   },
   "source": [
    "##helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5Gbtsl1JEGV"
   },
   "outputs": [],
   "source": [
    "def create_hidden_size(n_hidden_layers = 3, n_latent_factors = 32):\n",
    "  \"\"\"Sizes of each hidden layer, decreasing order\"\"\"\n",
    "  hidden_size = [n_latent_factors*2**i for i in reversed(range(n_hidden_layers))]\n",
    "  return hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hpl15LyQlZ9F"
   },
   "source": [
    "#Create model with Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrtvnw-5u3FY"
   },
   "outputs": [],
   "source": [
    "#create autoencoder + ...\n",
    "#def create_model(n_users, n_items, l1_val=1e-6, l2_val=1e-5):\n",
    "def create_model(n_users,n_items,learning_rate, n_hidden_layers,n_latent_factors,l1=1e-5, l2=1e-4):\n",
    "\n",
    "  #hidden_size = create_hidden_size()\n",
    "  hidden_size = create_hidden_size(n_hidden_layers,n_latent_factors)\n",
    "\n",
    "  #create 4 input layers\n",
    "  uii = Input(shape=(n_items,), name='uii')\n",
    "  umi = Input(shape=(n_items,), name='umi') # is a neighbour of ui\n",
    "\n",
    "  vji = Input(shape=(n_users,), name='vji')\n",
    "  vni = Input(shape=(n_users,), name='vni') # is a neighour of vj\n",
    "\n",
    "  #user autoencoder\n",
    "  encoded = uii\n",
    "  for nn in hidden_size[:-1]:\n",
    "      encoded = Dense(nn, activation='relu', \n",
    "                      kernel_initializer='he_uniform',\n",
    "                      # kernel_regularizer=l2(l2_val)\n",
    "                      )(encoded)\n",
    "      # encoded = BatchNormalization()(encoded)\n",
    "      # encoded = Dropout(0.2)(encoded)\n",
    "\n",
    "  encoded = Dense(hidden_size[-1], activation='relu', \n",
    "                  kernel_initializer='he_uniform',\n",
    "                  # kernel_regularizer=l2(l2_val),\n",
    "                  name='encoder')(encoded) \n",
    "\n",
    "  hidden_size.reverse()\n",
    "  decoded = encoded\n",
    "  for nn in hidden_size[1:]:\n",
    "    decoded = Dense(nn, activation='relu', \n",
    "                    kernel_initializer='he_uniform',\n",
    "                    # kernel_regularizer=l2(l2_val)\n",
    "                    )(decoded)\n",
    "    # decoded = BatchNormalization()(decoded)\n",
    "    # decoded = Dropout(0.2)(decoded)\n",
    "  decoded = Dense(n_items, activation='relu',\n",
    "                  kernel_initializer='he_uniform',\n",
    "                  # kernel_regularizer=l2(l2_val), \n",
    "                  name='decoder')(decoded)\n",
    "\n",
    "  #for item autoencoder\n",
    "  #hidden_size = create_hidden_size() #reset hidden size\n",
    "  hidden_size = create_hidden_size(n_hidden_layers,n_latent_factors)#reset hidden size\n",
    "  encoded2 = vji\n",
    "  for nn in hidden_size[:-1]:\n",
    "      encoded2 = Dense(nn, activation='relu', \n",
    "                       kernel_initializer='he_uniform',\n",
    "                      #  kernel_regularizer=l2(l2_val)\n",
    "                       )(encoded2) \n",
    "      # encoded2 = BatchNormalization()(encoded2)\n",
    "      # encoded2 = Dropout(0.2)(encoded2)\n",
    "\n",
    "  encoded2 = Dense(hidden_size[-1], activation='relu',\n",
    "                   kernel_initializer='he_uniform',\n",
    "                  #  kernel_regularizer=l2(l2_val), \n",
    "                   name='encoder2')(encoded2) \n",
    "\n",
    "  hidden_size.reverse()\n",
    "  decoded2 = encoded2\n",
    "  for nn in hidden_size[1:]:\n",
    "    decoded2 = Dense(nn, activation='relu',\n",
    "                     kernel_initializer='he_uniform',\n",
    "                    #  kernel_regularizer=l2(l2_val)\n",
    "                     )(decoded2)\n",
    "    # decoded2 = BatchNormalization()(decoded2)\n",
    "    # decoded2 = Dropout(0.2)(decoded2)\n",
    "\n",
    "  decoded2 = Dense(n_users, activation='relu',\n",
    "                   kernel_initializer='he_uniform',\n",
    "                    # kernel_regularizer=l2(l2_val), \n",
    "                   name='decoder2')(decoded2)\n",
    "\n",
    "  #prod = layers.dot([encoded, encoded2], axes=1, name='DotProduct')\n",
    "  #V2: replace dot prod with mlp\n",
    "  concat = layers.concatenate([encoded, encoded2])\n",
    "  mlp = concat\n",
    "  for i in range(3,-1,-1):\n",
    "    if i == 0:\n",
    "      mlp = Dense(1, activation='sigmoid',\n",
    "                  name=\"output\")(mlp)\n",
    "    else:\n",
    "      mlp = Dense(8*2**i, activation='sigmoid',\n",
    "                  # kernel_regularizer=l1_l2(l1_val,l2_val),\n",
    "                  # kernel_initializer=ÃŸ'he_uniform'\n",
    "                  )(mlp)\n",
    "      if i >= 2:\n",
    "        mlp = BatchNormalization()(mlp)\n",
    "        mlp = Dropout(0.2)(mlp)\n",
    "\n",
    "  model = Model(inputs=[uii,  vji], outputs=[decoded,decoded2, mlp])\n",
    "  adadelta = tf.keras.optimizers.Adadelta(learning_rate)\n",
    "  model.compile(optimizer='adadelta', loss={'output':'binary_crossentropy', \n",
    "                                        'decoder':'mean_squared_error', \n",
    "                                        'decoder2':'mean_squared_error'\n",
    "                                        }, \n",
    "                metrics={'output':['binary_accuracy',\n",
    "                                  #  'Precision', 'AUC'\n",
    "                                   ], \n",
    "                         'decoder':'mse', \n",
    "                         'decoder2':'mse'})\n",
    "\n",
    "  #model.summary()\n",
    "\n",
    "  return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 995
    },
    "colab_type": "code",
    "id": "Rckg9TjWdeHm",
    "outputId": "b9ae67ef-7497-45cd-8ec2-cab76a676e07"
   },
   "outputs": [],
   "source": [
    "#model = create_model(n_users, n_items)\n",
    "model1 = create_model(n_users,n_items,args.lr[3],args.hidden_layers[0], args.hidden_factors[3], args.regularizer[1],args.regularizer[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tRo85iwwhy3-",
    "outputId": "3ba9f424-a25f-4c20-c9d1-8e83a5eb2d36"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model3.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hL6lccOaleLN"
   },
   "source": [
    "###Create data generator using rating matrix\n",
    "\n",
    "It takes rating matrix and generate a sequence of users, items, and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzlkixAH9q9F"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataset, rating_matrix, batch_size=32,  shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = self.dataset.index\n",
    "        self.rating_matrix = rating_matrix\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return math.floor(len(self.dataset) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        idxs = [i for i in range(index*self.batch_size,(index+1)*self.batch_size)]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.indexes[k] for k in idxs]\n",
    "\n",
    "        # Generate data\n",
    "        uids = self.dataset.iloc[list_IDs_temp,[0]].to_numpy().reshape(-1)\n",
    "        iids = self.dataset.iloc[list_IDs_temp,[1]].to_numpy().reshape(-1)\n",
    "        # print(uids)\n",
    "        Users = np.stack([rating_matrix[row] for row in uids])\n",
    "        Items = np.stack([rating_matrix[:, col] for col in iids])\n",
    "        ratings = self.dataset.iloc[list_IDs_temp,[2]].to_numpy().reshape(-1)\n",
    "        \n",
    "        # ratings = keras.utils.to_categorical(rr)\n",
    "        # print(Items, type(Items))\n",
    "        # print(ratings, type(ratings))\n",
    "        \n",
    "        return (Users, Items),(Users, Items, ratings)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "        'hidden_layers': [3,10],\n",
    "        'hidden_factors': [8,16,32,64],\n",
    "        'batch':[128,256,512,1024],\n",
    "        'regularizer': [1e-4,1e-6,1e-8],\n",
    "        'lr':[0.0001 ,0.0005, 0.001, 0.005],\n",
    "    })     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in args.lr:\n",
    "    for j in args.batch:\n",
    "        for k in args.hidden_factors:\n",
    "            for l in args.regularizer:\n",
    "                model1=create_model(n_users,n_items,i,k,l,l)\n",
    "                traindatagenerator = DataGenerator(train, rating_matrix,batch_size=j,shuffle=True)\n",
    "                history = model1.fit(traindatagenerator, epochs=100,verbose=0)\n",
    "                testdatagenerator = DataGenerator(test, rating_matrix,batch_size=j)\n",
    "                results = model1.evaluate(testdatagenerator,verbose=0)\n",
    "                print('RESULT: lr=',i, 'regularization=',l, ' batch=', j, 'hidden factors=', k, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XW6ZseFXRQzV"
   },
   "source": [
    "##Training with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "colab_type": "code",
    "id": "0-yRouiTlUaA",
    "outputId": "0b4dfd36-bb42-4ba2-949b-4061529e2802"
   },
   "outputs": [],
   "source": [
    "traindatagenerator = DataGenerator(train, rating_matrix,shuffle=True)\n",
    "\n",
    "history = model.fit(traindatagenerator, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7kmaOr4mZ7o"
   },
   "outputs": [],
   "source": [
    "##This is for normal training (old)\n",
    "# history = model.fit({'uii':ext_user_matrix, 'vji':rating_matrix.T}, \n",
    "#            {'decoder':ext_user_matrix, 'decoder2':rating_matrix.T, 'output':np.diag(ext_user_matrix)},\n",
    "#            epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2E8-5W-Vis_e"
   },
   "source": [
    "## Plot losses\n",
    "\n",
    "There are several losses, pick the one we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nibfBfDYCVQ"
   },
   "outputs": [],
   "source": [
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "pd.Series(history.history['output_binary_accuracy']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Error\")\n",
    "plt.legend(['loss','output_binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pyd1JY_tYilg"
   },
   "source": [
    "Let's now see how our model does! I'll do a small post-processing step to round off our prediction to the nearest integer. This is usually not done, and thus just a whimsical step, since the training ratings are all integers! There are better ways to encode this intger requirement (one-hot encoding!), but we won't discuss them in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iQQp_-5Yg8E"
   },
   "outputs": [],
   "source": [
    "testdatagenerator = DataGenerator(test, rating_matrix)\n",
    "\n",
    "results = model.evaluate(testdatagenerator)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsdDXeO8Ry7_"
   },
   "source": [
    "#References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKqSn4KnL2yQ"
   },
   "source": [
    "Input layer:\n",
    "\n",
    "- Embedding layer: [Link](https://gdcoder.com/-what-is-an-embedding-layer/)\n",
    "- Embedding lookup: [link text](https://keras.io/layers/embeddings/)\n",
    "- Multi input: [link text](https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mo Model 3a for implicit : autoencoders + MLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
